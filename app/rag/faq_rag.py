from dotenv import load_dotenv
load_dotenv()

import json
import pickle
import os
import numpy as np
from typing import List, Dict, Optional
import faiss
import logging

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# íŒŒì¼ ê²½ë¡œ
FAQ_JSON_PATH = os.path.join(os.path.dirname(__file__), 'hi_faq.json')
EMBEDDINGS_PATH = os.path.join(os.path.dirname(__file__), '..', '..', '..', 'data', 'faq_embeddings.pkl')

def check_dependencies():
    """AI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜ì¡´ì„± ë° ë²„ì „ ì²´í¬"""
    try:
        import torch
        import transformers
        import packaging
        import sentence_transformers
        
        logger.info(f"[ì˜ì¡´ì„± ì²´í¬] torch: {torch.__version__}")
        logger.info(f"[ì˜ì¡´ì„± ì²´í¬] transformers: {transformers.__version__}")
        logger.info(f"[ì˜ì¡´ì„± ì²´í¬] packaging: {packaging.__version__}")
        logger.info(f"[ì˜ì¡´ì„± ì²´í¬] sentence-transformers: {sentence_transformers.__version__}")
        
        # í˜¸í™˜ì„± ì²´í¬
        torch_version = tuple(map(int, torch.__version__.split('.')[:2]))
        if torch_version < (2, 0):
            logger.warning(f"âš ï¸ torch ë²„ì „ì´ ë‚®ìŠµë‹ˆë‹¤: {torch.__version__} (ê¶Œì¥: 2.0+)")
        
        return True
    except ImportError as e:
        logger.error(f"âŒ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì‹¤íŒ¨: {e}")
        return False
    except Exception as e:
        logger.error(f"âŒ ì˜ì¡´ì„± ì²´í¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

# 1. FAQ ë°ì´í„° ë¡œë”©
def load_faq_data() -> Optional[List[Dict]]:
    """FAQ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ë¡œë”©"""
    try:
        if not os.path.exists(FAQ_JSON_PATH):
            logger.error(f"FAQ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {FAQ_JSON_PATH}")
            return None
            
        with open(FAQ_JSON_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)
            logger.info(f"FAQ ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(data)}ê°œ í•­ëª©")
            return data
    except json.JSONDecodeError as e:
        logger.error(f"FAQ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None
    except Exception as e:
        logger.error(f"FAQ ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return None

# 2. ì„ë² ë”© ìƒì„±/ì €ì¥/ëª¨ë¸ ë¡œë”© (ìš´ì˜ ì„œë²„ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
def get_model():
    """SentenceTransformer ëª¨ë¸ì„ ì•ˆì „í•˜ê²Œ ë¡œë”©"""
    try:
        # ì˜ì¡´ì„± ë¨¼ì € ì²´í¬
        if not check_dependencies():
            raise ImportError("í•„ìˆ˜ ì˜ì¡´ì„±ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤")
            
        from sentence_transformers import SentenceTransformer
        import torch
        
        # CPU ì‚¬ìš© ê°•ì œ
        device = 'cpu'
        logger.info("CPU ì‚¬ìš©ìœ¼ë¡œ ì„¤ì •ë¨")
        
        logger.info(f"SentenceTransformer ëª¨ë¸ ë¡œë”© ì¤‘... (device: {device})")
        model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', device=device)
        logger.info("âœ… SentenceTransformer ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        return model
        
    except ImportError as e:
        logger.error(f"âŒ SentenceTransformer import ì‹¤íŒ¨: {e}")
        raise
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        raise

def create_and_save_embeddings():
    """ì„ë² ë”© ìƒì„± ë° ì €ì¥ (ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”)"""
    try:
        faqs = load_faq_data()
        if not faqs:
            logger.error("FAQ ë°ì´í„°ê°€ ì—†ì–´ ì„ë² ë”©ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
            
        model = get_model()
        if not model:
            logger.error("ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ë¡œ ì„ë² ë”©ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
            
        logger.info("ì„ë² ë”© ìƒì„± ì¤‘...")
        texts = [f"Q: {faq['question']}\nA: {faq['content']}" for faq in faqs]
        embeddings = model.encode(texts, show_progress_bar=True)
        
        faq_embeddings = [
            {
                'faq': faq,
                'embedding': emb
            }
            for faq, emb in zip(faqs, embeddings)
        ]
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(EMBEDDINGS_PATH), exist_ok=True)
        
        with open(EMBEDDINGS_PATH, 'wb') as f:
            pickle.dump(faq_embeddings, f)
        
        logger.info(f"âœ… ì„ë² ë”© {len(faq_embeddings)}ê°œ ì €ì¥ ì™„ë£Œ: {EMBEDDINGS_PATH}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ì„ë² ë”© ìƒì„±/ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def load_embeddings() -> Optional[List[Dict]]:
    """ì„ë² ë”©ì„ ì•ˆì „í•˜ê²Œ ë¡œë”©"""
    try:
        if not os.path.exists(EMBEDDINGS_PATH):
            logger.warning(f"ì„ë² ë”© íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {EMBEDDINGS_PATH}")
            return None
            
        with open(EMBEDDINGS_PATH, 'rb') as f:
            data = pickle.load(f)
            logger.info(f"ì„ë² ë”© ë¡œë”© ì™„ë£Œ: {len(data)}ê°œ í•­ëª©")
            return data
    except Exception as e:
        logger.error(f"ì„ë² ë”© ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

def cosine_similarity(a, b):
    """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ì•ˆì „í•œ êµ¬í˜„)"""
    try:
        a = np.array(a)
        b = np.array(b)
        norm_a = np.linalg.norm(a)
        norm_b = np.linalg.norm(b)
        
        if norm_a == 0 or norm_b == 0:
            return 0.0
            
        return np.dot(a, b) / (norm_a * norm_b)
    except Exception as e:
        logger.error(f"ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return 0.0

# 3. FAISS ì¸ë±ìŠ¤ ë° ì„ë² ë”© ë©”ëª¨ë¦¬ ìºì‹±
faq_embeddings = None
faq_list = None
faiss_index = None
model = None  # ëª¨ë¸ë„ ì „ì—­ìœ¼ë¡œ ë¯¸ë¦¬ ë¡œë”©

def initialize_faq_system():
    """FAQ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ì•ˆì „í•œ ì´ˆê¸°í™”)"""
    global faq_embeddings, faq_list, faiss_index, model
    
    try:
        # ì˜ì¡´ì„± ì²´í¬
        if not check_dependencies():
            logger.error("ì˜ì¡´ì„± ì²´í¬ ì‹¤íŒ¨ - FAQ ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        # ì„ë² ë”© ë¡œë”©
        if os.path.exists(EMBEDDINGS_PATH):
            loaded = load_embeddings()
            if loaded:
                faq_list = [item['faq'] for item in loaded]
                faq_embeddings = np.array([item['embedding'] for item in loaded], dtype='float32')
                
                # FAISS ì¸ë±ìŠ¤ ìƒì„±
                faiss_index = faiss.IndexFlatL2(faq_embeddings.shape[1])
                faiss_index.add(faq_embeddings)
                
                # ëª¨ë¸ ë¯¸ë¦¬ ë¡œë”©
                model = get_model()
                
                logger.info("âœ… FAQ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
                return True
            else:
                logger.error("ì„ë² ë”© ë¡œë”© ì‹¤íŒ¨")
                return False
        else:
            logger.warning(f"FAQ ì„ë² ë”© íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {EMBEDDINGS_PATH}")
            return False
            
    except Exception as e:
        logger.error(f"FAQ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

# query ì„ë² ë”© ìƒì„± í•¨ìˆ˜ (ì‹¤ì œ ìš´ì˜ ì‹œ ì™¸ë¶€ APIë¡œ ëŒ€ì²´ ê°€ëŠ¥)
def get_query_embedding(query: str) -> Optional[np.ndarray]:
    """ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± (ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”)"""
    global model
    
    try:
        if model is None:
            model = get_model()
            if model is None:
                logger.error("ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
                return None
        
        text = query.strip()
        if not text:
            logger.warning("ë¹ˆ ì¿¼ë¦¬ì…ë‹ˆë‹¤")
            return None
            
        embedding = model.encode([text])[0].astype('float32')
        return embedding
        
    except Exception as e:
        logger.error(f"ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def search_faqs(query: str, top_n: int = 3) -> List[Dict]:
    """
    FAQ ê²€ìƒ‰ (ì•ˆì „í•œ êµ¬í˜„)
    query: ì‚¬ìš©ìì˜ ì§ˆë¬¸
    top_n: ë°˜í™˜í•  FAQ ê°œìˆ˜
    return: [{'faq': ..., 'score': ...}, ...]
    """
    try:
        if faiss_index is None or faq_embeddings is None or faq_list is None:
            logger.warning("FAQ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return []
        
        if not query or not query.strip():
            logger.warning("ë¹ˆ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return []
        
        query_emb = get_query_embedding(query)
        if query_emb is None:
            logger.error("ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
            return []
            
        query_emb = query_emb.reshape(1, -1)
        D, I = faiss_index.search(query_emb, min(top_n, len(faq_list)))
        
        results = []
        for idx, score in zip(I[0], D[0]):
            if idx < 0 or idx >= len(faq_list):
                continue
            results.append({
                'faq': faq_list[idx],
                'score': float(-score)  # FAISS L2 ê±°ë¦¬ì´ë¯€ë¡œ, -scoreë¡œ ìœ ì‚¬ë„ì²˜ëŸ¼ ì‚¬ìš©
            })
        
        logger.info(f"FAQ ê²€ìƒ‰ ì™„ë£Œ: ì¿¼ë¦¬='{query}', ê²°ê³¼={len(results)}ê°œ")
        return results
        
    except Exception as e:
        logger.error(f"FAQ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return []

# ì„œë²„ ì‹œì‘ ì‹œ FAQ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
try:
    success = initialize_faq_system()
    if success:
        logger.info("ğŸš€ FAQ ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤")
    else:
        logger.warning("âš ï¸ FAQ ì‹œìŠ¤í…œ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
except Exception as e:
    logger.error(f"âŒ FAQ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    create_and_save_embeddings() 