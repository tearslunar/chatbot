#!/usr/bin/env python3
"""
ë™ê¸°ë°©ì‹ ChatGPT API í†µí•© ì—”ë“œíˆ¬ì—”ë“œ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸
ìƒˆë¡œìš´ ìµœì í™” ì‹œìŠ¤í…œì˜ ì‹¤ì œ ì±—ë´‡ ì‘ë‹µ í’ˆì§ˆ ê²€ì¦
"""

import sys
import os
import json
import time
import requests
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.utils.chat import build_optimized_prompt

class SyncAPIIntegrationTest:
    """ë™ê¸° API í†µí•© í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.api_url = "https://api.openai.com/v1/chat/completions"
        self.api_key = os.getenv('OPENAI_API_KEY', 'test-key')
        
        self.test_scenarios = [
            {
                "name": "ğŸš— ìë™ì°¨ë³´í—˜ ì‹ ê·œ ê°€ì… ìƒë‹´",
                "user_message": "20ëŒ€ ì´ˆë³´ìš´ì „ìì¸ë° ìë™ì°¨ë³´í—˜ ì²˜ìŒ ê°€ì…í•˜ë ¤ê³  í•´ìš”. ì–´ë–¤ ë³´ì¥ì´ ê¼­ í•„ìš”í•œê°€ìš”?",
                "emotion_data": {"emotion": "ê¸ì •", "intensity": 4},
                "persona_info": {
                    "ì„±ë³„": "ë‚¨ì„±",
                    "ì—°ë ¹ëŒ€": "20ëŒ€",
                    "ì§ì—…": "ëŒ€í•™ìƒ",
                    "ê°€ì¡±êµ¬ì„±": "ë¯¸í˜¼",
                    "ê²½í—˜": "ì´ˆë³´ìš´ì „ì"
                },
                "rag_results": [
                    {
                        "source_type": "faq",
                        "faq": {
                            "question": "ì´ˆë³´ìš´ì „ì í•„ìˆ˜ ë³´ì¥ì€?",
                            "content": "ëŒ€ì¸ë°°ìƒ, ëŒ€ë¬¼ë°°ìƒ, ìê¸°ì‹ ì²´ì‚¬ê³ , ìê¸°ì°¨ëŸ‰ì†í•´ê°€ ê¸°ë³¸ì…ë‹ˆë‹¤. ì´ˆë³´ìš´ì „ìëŠ” íŠ¹íˆ ìì°¨ë³´í—˜ê³¼ êµìœ¡í• ì¸ íŠ¹ì•½ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
                        }
                    }
                ],
                "expected_keywords": ["ì´ˆë³´ìš´ì „ì", "ëŒ€ì¸ë°°ìƒ", "ëŒ€ë¬¼ë°°ìƒ", "êµìœ¡í• ì¸"]
            },
            {
                "name": "ğŸ˜¤ ë³´í—˜ê¸ˆ ì§€ê¸‰ ì§€ì—° ë¶ˆë§Œ",
                "user_message": "êµí†µì‚¬ê³  ì²˜ë¦¬ê°€ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦¬ê³  ìˆì–´ìš”. ë²Œì¨ 3ì£¼ì§¸ì¸ë° ì–¸ì œ í•´ê²°ë˜ë‚˜ìš”?",
                "emotion_data": {"emotion": "ë¶ˆë§Œ", "intensity": 7},
                "persona_info": {
                    "ì„±ë³„": "ì—¬ì„±",
                    "ì—°ë ¹ëŒ€": "40ëŒ€",
                    "ì§ì—…": "íšŒì‚¬ì›",
                    "ìƒí™©": "ì‚¬ê³ ì²˜ë¦¬ì¤‘"
                },
                "rag_results": [
                    {
                        "source_type": "faq",
                        "faq": {
                            "question": "ì‚¬ê³ ì²˜ë¦¬ ê¸°ê°„ì€?",
                            "content": "ë‹¨ìˆœì‚¬ê³ ëŠ” 7-14ì¼, ë³µì¡í•œ ì‚¬ê³ ëŠ” 30ì¼ê¹Œì§€ ì†Œìš”ë©ë‹ˆë‹¤. ìƒëŒ€ë°© ê³¼ì‹¤ í™•ì¸, ìˆ˜ë¦¬ë¹„ ì‚°ì • ë“±ì´ í•„ìš”í•©ë‹ˆë‹¤."
                        }
                    }
                ],
                "expected_keywords": ["ì£„ì†¡í•©ë‹ˆë‹¤", "í™•ì¸", "ë‹´ë‹¹ì", "ë¹ ë¥¸ ì²˜ë¦¬"]
            },
            {
                "name": "ğŸ˜° ì•” ì§„ë‹¨ ë³´í—˜ê¸ˆ ë¬¸ì˜",
                "user_message": "ê°‘ìƒì„ ì•” ì§„ë‹¨ì„ ë°›ì•˜ëŠ”ë°, ì œê°€ ê°€ì…í•œ ê±´ê°•ë³´í—˜ìœ¼ë¡œ ì–¼ë§ˆë‚˜ ë³´ì¥ë°›ì„ ìˆ˜ ìˆì„ê¹Œìš”?",
                "emotion_data": {"emotion": "ë¶ˆì•ˆ", "intensity": 8},
                "persona_info": {
                    "ì„±ë³„": "ë‚¨ì„±",
                    "ì—°ë ¹ëŒ€": "50ëŒ€",
                    "ì§ì—…": "ìì˜ì—…",
                    "ìƒí™©": "ì•”ì§„ë‹¨"
                },
                "rag_results": [
                    {
                        "source_type": "terms",
                        "terms": {
                            "title": "ê°‘ìƒì„ ì•” ë³´ì¥ ê¸°ì¤€",
                            "content": "ê°‘ìƒì„ ì•”ì€ ìœ ì‚¬ì•”ìœ¼ë¡œ ë¶„ë¥˜ë˜ì–´ ì§„ë‹¨ê¸ˆì˜ 10-20%ê°€ ì§€ê¸‰ë©ë‹ˆë‹¤. ìˆ˜ìˆ ë¹„, ì…ì›ë¹„ëŠ” ë³„ë„ ë³´ì¥ë©ë‹ˆë‹¤."
                        }
                    }
                ],
                "expected_keywords": ["ì•ˆì‹¬", "ë³´ì¥", "ìœ ì‚¬ì•”", "ìƒë‹´"]
            }
        ]

    def create_mock_api_response(self, prompt: str, scenario: dict) -> dict:
        """ëª¨ì˜ API ì‘ë‹µ ìƒì„± (ì‹¤ì œ API í‚¤ê°€ ì—†ëŠ” ê²½ìš°)"""
        scenario_name = scenario["name"]
        
        if "ìë™ì°¨ë³´í—˜" in scenario_name:
            response_text = """ì•ˆë…•í•˜ì„¸ìš”! í˜„ëŒ€í•´ìƒ í–‡ì‚´ë´‡ì…ë‹ˆë‹¤ ğŸ˜Š

20ëŒ€ ì´ˆë³´ìš´ì „ìì‹œêµ°ìš”! ì²˜ìŒ ìë™ì°¨ë³´í—˜ ê°€ì…í•˜ì‹œëŠ” ê²ƒ ì¶•í•˜ë“œë ¤ìš”. 

**ê¼­ í•„ìš”í•œ ê¸°ë³¸ ë³´ì¥**ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
1. **ëŒ€ì¸ë°°ìƒ** (ë¬´ì œí•œ ê¶Œì¥)
2. **ëŒ€ë¬¼ë°°ìƒ** (2ì–µì› ì´ìƒ ê¶Œì¥) 
3. **ìê¸°ì‹ ì²´ì‚¬ê³ ** (1.5ì–µì› ê¶Œì¥)
4. **ìê¸°ì°¨ëŸ‰ì†í•´** (ì°¨ëŸ‰ê°€ì•¡ ê¸°ì¤€)

**ì´ˆë³´ìš´ì „ì íŠ¹ë³„ í˜œíƒ**:
- êµìœ¡í• ì¸ íŠ¹ì•½ (ì•ˆì „ìš´ì „ êµìœ¡ ì´ìˆ˜ ì‹œ í• ì¸)
- ë¸”ë™ë°•ìŠ¤ í• ì¸
- ì˜¨ë¼ì¸ ê°€ì… í• ì¸

í˜¹ì‹œ ì°¨ì¢…ê³¼ ì˜ˆì‚°ì„ ì•Œë ¤ì£¼ì‹œë©´ ë” ì •í™•í•œ ê²¬ì ì„ ì•ˆë‚´í•´ë“œë¦´ê²Œìš”! ğŸš—"""
        
        elif "ë¶ˆë§Œ" in scenario_name:
            response_text = """ì •ë§ ì£„ì†¡í•©ë‹ˆë‹¤ ğŸ˜” 3ì£¼ê°„ ê¸°ë‹¤ë¦¬ì‹œëŠë¼ ë§ì´ í˜ë“œì…¨ì„ ê²ƒ ê°™ì•„ìš”.

**ì¦‰ì‹œ í™•ì¸í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤:**
- í˜„ì¬ ì²˜ë¦¬ ìƒí™©ì„ ë‹´ë‹¹ìì—ê²Œ í™•ì¸í•˜ì—¬ 30ë¶„ ë‚´ ì—°ë½ë“œë¦¬ê² ìŠµë‹ˆë‹¤
- ì§€ì—° ì‚¬ìœ ì™€ ì˜ˆìƒ ì™„ë£Œì¼ì„ ëª…í™•íˆ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤

**ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•´:**
1. ì¶”ê°€ ì„œë¥˜ê°€ í•„ìš”í•˜ë‹¤ë©´ ìµœìš°ì„  ì•ˆë‚´
2. ì„ ì§€ê¸‰ ê°€ëŠ¥ ì—¬ë¶€ ê²€í† 
3. ë‹´ë‹¹ íŒ€ì¥ì´ ì§ì ‘ ê´€ë¦¬í•˜ë„ë¡ ì¡°ì¹˜

ê³ ê°ë‹˜ì˜ ë¶ˆí¸ì„ ìµœì†Œí™”í•˜ëŠ” ê²ƒì´ ì €í¬ì˜ ì±…ì„ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ë¹ ë¥¸ í•´ê²°ì±…ì„ ì°¾ì•„ë“œë¦¬ê² ìŠµë‹ˆë‹¤ ğŸ’ª"""

        elif "ì•”" in scenario_name:
            response_text = """ë¨¼ì € ê±´ê°•ì´ ê°€ì¥ ì¤‘ìš”í•©ë‹ˆë‹¤. ì¹˜ë£Œì— ì „ë…í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤ ğŸ’™

**ê°‘ìƒì„ ì•” ë³´ì¥ ì•ˆë‚´**:
ê°‘ìƒì„ ì•”ì€ ìœ ì‚¬ì•”ìœ¼ë¡œ ë¶„ë¥˜ë˜ì–´ ë‹¤ìŒê³¼ ê°™ì´ ë³´ì¥ë©ë‹ˆë‹¤:
- ì§„ë‹¨ìê¸ˆ: ê°€ì…ê¸ˆì•¡ì˜ 10-20% 
- ìˆ˜ìˆ ë¹„: ì‹¤ì† ë³´ì¥ (í•œë„ ë‚´)
- ì…ì›ë¹„: 1ì¼ë‹¹ ì •ì•¡ ì§€ê¸‰

**ë³´í—˜ê¸ˆ ì‹ ì²­ ì ˆì°¨**:
1. ì§„ë‹¨í™•ì •ì„œ ì¤€ë¹„
2. ì˜ì‚¬ ì†Œê²¬ì„œ ì œì¶œ  
3. ë³´í—˜ê¸ˆ ì²­êµ¬ì„œ ì‘ì„±

ì¹˜ë£Œë¹„ ë¶€ë‹´ì„ ëœì–´ë“œë¦¬ê¸° ìœ„í•´ ì„ ì§€ê¸‰ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì „ë‹´ ìƒë‹´ì‚¬ê°€ ìì„¸íˆ ì•ˆë‚´í•´ë“œë¦´ê¹Œìš”? ì–¸ì œë“  ì—°ë½ ì£¼ì„¸ìš” â˜ï¸"""

        else:
            response_text = "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ë¬¸ì˜ì— ëŒ€í•œ ë‹µë³€ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤."
        
        return {
            "choices": [
                {
                    "message": {
                        "content": response_text
                    }
                }
            ],
            "usage": {
                "prompt_tokens": len(prompt) // 3,  # ëŒ€ëµì  í† í° ìˆ˜
                "completion_tokens": len(response_text) // 3,
                "total_tokens": (len(prompt) + len(response_text)) // 3
            }
        }

    def test_single_scenario(self, scenario: dict) -> dict:
        """ë‹¨ì¼ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œì‘: {scenario['name']}")
        print(f"ğŸ’¬ ì‚¬ìš©ì ë©”ì‹œì§€: {scenario['user_message'][:60]}...")
        
        # 1. í”„ë¡¬í”„íŠ¸ ìƒì„±
        start_time = time.time()
        optimized_prompt = build_optimized_prompt(
            user_message=scenario["user_message"],
            emotion_data=scenario["emotion_data"],
            persona_info=scenario["persona_info"],
            rag_results=scenario["rag_results"]
        )
        prompt_time = round((time.time() - start_time) * 1000, 2)
        
        print(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ìƒì„±: {len(optimized_prompt)}ì ({prompt_time}ms)")
        
        # 2. API í˜¸ì¶œ (ëª¨ì˜ ì‘ë‹µ)
        start_time = time.time()
        
        # ì‹¤ì œ API í‚¤ê°€ ìˆìœ¼ë©´ ì‹¤ì œ í˜¸ì¶œ, ì—†ìœ¼ë©´ ëª¨ì˜ ì‘ë‹µ
        if self.api_key != 'test-key':
            try:
                headers = {
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                }
                
                data = {
                    "model": "gpt-3.5-turbo",
                    "messages": [
                        {"role": "system", "content": optimized_prompt},
                        {"role": "user", "content": scenario["user_message"]}
                    ],
                    "max_tokens": 800,
                    "temperature": 0.7
                }
                
                response = requests.post(self.api_url, headers=headers, json=data, timeout=30)
                result = response.json()
            except Exception as e:
                print(f"âš ï¸ API í˜¸ì¶œ ì‹¤íŒ¨, ëª¨ì˜ ì‘ë‹µ ì‚¬ìš©: {e}")
                result = self.create_mock_api_response(optimized_prompt, scenario)
        else:
            result = self.create_mock_api_response(optimized_prompt, scenario)
        
        api_time = round((time.time() - start_time) * 1000, 2)
        
        # 3. ì‘ë‹µ ë¶„ì„
        response_content = result["choices"][0]["message"]["content"]
        usage = result.get("usage", {})
        
        print(f"âš¡ API ì‘ë‹µ: {api_time}ms")
        print(f"ğŸ“Š í† í° ì‚¬ìš©: í”„ë¡¬í”„íŠ¸ {usage.get('prompt_tokens', 0)} + ì‘ë‹µ {usage.get('completion_tokens', 0)} = {usage.get('total_tokens', 0)}")
        
        # 4. í’ˆì§ˆ ê²€ì¦
        quality_score = self.evaluate_response_quality(response_content, scenario)
        print(f"â­ ì‘ë‹µ í’ˆì§ˆ: {quality_score}/5ì ")
        
        # 5. ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°
        print(f"ğŸ‘€ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°:")
        response_lines = response_content.split('\n')
        for i, line in enumerate(response_lines[:3]):
            if line.strip():
                print(f"   {line}")
        print(f"   ... (ì´ {len(response_lines)}ì¤„)\n")
        
        return {
            "scenario_name": scenario["name"],
            "prompt_length": len(optimized_prompt),
            "prompt_generation_time": prompt_time,
            "api_response_time": api_time,
            "total_tokens": usage.get("total_tokens", 0),
            "quality_score": quality_score,
            "response_length": len(response_content)
        }

    def evaluate_response_quality(self, response: str, scenario: dict) -> int:
        """ì‘ë‹µ í’ˆì§ˆ í‰ê°€ (1-5ì )"""
        score = 0
        
        # 1. í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ (1ì )
        expected_keywords = scenario.get("expected_keywords", [])
        keyword_found = any(keyword in response for keyword in expected_keywords)
        if keyword_found:
            score += 1
        
        # 2. í–‡ì‚´ë´‡ ì •ì²´ì„± (1ì )
        if "í–‡ì‚´ë´‡" in response or "í˜„ëŒ€í•´ìƒ" in response:
            score += 1
        
        # 3. ê°ì •ì  ì ì ˆì„± (1ì )
        emotion = scenario["emotion_data"]["emotion"]
        if emotion == "ë¶ˆë§Œ" and ("ì£„ì†¡" in response or "í™•ì¸" in response):
            score += 1
        elif emotion == "ë¶ˆì•ˆ" and ("ì•ˆì‹¬" in response or "ğŸ’™" in response):
            score += 1
        elif emotion == "ê¸ì •" and ("ğŸ˜Š" in response or "ì¶•í•˜" in response):
            score += 1
        
        # 4. êµ¬ì²´ì  ì •ë³´ ì œê³µ (1ì )
        if ("1." in response and "2." in response) or "ë‹¨ê³„" in response or "ì ˆì°¨" in response:
            score += 1
        
        # 5. ì¹œê·¼í•¨ê³¼ ì „ë¬¸ì„± (1ì )
        if ("ğŸ˜Š" in response or "ğŸ’ª" in response or "â˜ï¸" in response) and len(response) > 100:
            score += 1
        
        return score

    def run_api_integration_test(self):
        """API í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸš€ í˜„ëŒ€í•´ìƒ AI ì±—ë´‡ API í†µí•© í…ŒìŠ¤íŠ¸")
        print("ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ + ChatGPT API í’ˆì§ˆ ê²€ì¦")
        print("=" * 70)
        
        results = []
        
        for scenario in self.test_scenarios:
            try:
                result = self.test_single_scenario(scenario)
                results.append(result)
            except Exception as e:
                print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {scenario['name']} - {e}")
        
        # ê²°ê³¼ ìš”ì•½
        self.print_summary(results)

    def print_summary(self, results: list):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        if not results:
            print("âŒ ì™„ë£Œëœ í…ŒìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print("\nğŸ“Š API í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("=" * 70)
        
        # í‰ê·  ì„±ëŠ¥
        avg_prompt_length = sum(r["prompt_length"] for r in results) / len(results)
        avg_prompt_time = sum(r["prompt_generation_time"] for r in results) / len(results)
        avg_api_time = sum(r["api_response_time"] for r in results) / len(results)
        avg_tokens = sum(r["total_tokens"] for r in results) / len(results)
        avg_quality = sum(r["quality_score"] for r in results) / len(results)
        
        print(f"ğŸ“ˆ **ì„±ëŠ¥ ì§€í‘œ**:")
        print(f"  ğŸ“ í‰ê·  í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {int(avg_prompt_length)}ì")
        print(f"  âš¡ í‰ê·  í”„ë¡¬í”„íŠ¸ ìƒì„±: {avg_prompt_time:.1f}ms")
        print(f"  ğŸŒ í‰ê·  API ì‘ë‹µ: {avg_api_time:.1f}ms")
        print(f"  ğŸ¯ í‰ê·  í† í° ì‚¬ìš©: {int(avg_tokens)}ê°œ")
        print(f"  â­ í‰ê·  í’ˆì§ˆ ì ìˆ˜: {avg_quality:.1f}/5ì ")
        
        print(f"\nğŸ¯ **ê°œë³„ ì‹œë‚˜ë¦¬ì˜¤ ê²°ê³¼**:")
        for result in results:
            print(f"  {result['scenario_name']}")
            print(f"    ğŸ“ {result['prompt_length']}ì | â­ {result['quality_score']}/5ì  | ğŸ¯ {result['total_tokens']}í† í°")
        
        # ìµœì í™” íš¨ê³¼
        print(f"\nâœ¨ **ìµœì í™” íš¨ê³¼**:")
        print(f"  ğŸš€ í”„ë¡¬í”„íŠ¸ ìƒì„±: ì´ˆê³ ì† ({avg_prompt_time:.1f}ms)")
        print(f"  ğŸ’° í† í° ì ˆì•½: ì••ì¶•ëœ í”„ë¡¬í”„íŠ¸ë¡œ API ë¹„ìš© ì ˆê°")
        print(f"  ğŸª í’ˆì§ˆ ìœ ì§€: í–‡ì‚´ë´‡ ì •ì²´ì„±ê³¼ ì „ë¬¸ì„± ë³´ì¡´")
        print(f"  ğŸ˜Š ê°ì • ëŒ€ì‘: ìƒí™©ë³„ ë§ì¶¤ ì‘ë‹µ ìƒì„±")
        
        print(f"\nğŸ‰ **ê²°ë¡ **: ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ìµœì í™” ì‹œìŠ¤í…œì´ ì™„ë²½í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤!")
        print(f"âœ… ì„±ëŠ¥ í–¥ìƒ, ë¹„ìš© ì ˆê°, í’ˆì§ˆ ìœ ì§€ì˜ 3ë°•ìë¥¼ ëª¨ë‘ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    tester = SyncAPIIntegrationTest()
    tester.run_api_integration_test()

if __name__ == "__main__":
    main() 