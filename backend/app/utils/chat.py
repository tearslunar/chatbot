from dotenv import load_dotenv
load_dotenv()
import os
import requests
from typing import List, Dict
from .emotion_response import emotion_response
from .prompt_manager import get_prompt_manager, PromptConfig, PromptMode
from fastapi import APIRouter, Request
from fastapi.responses import JSONResponse

# í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” (ì„±ëŠ¥ ë° ê¸¸ì´ ìµœì í™”)
_prompt_config = PromptConfig(
    mode=PromptMode.STANDARD,
    max_length=6000,
    max_history_turns=5,
    max_rag_results=3,
    rag_content_limit=300
)

# DEPRECATED - ìƒˆë¡œìš´ ì‹œìŠ¤í…œìœ¼ë¡œ êµì²´ë¨
PERSONA_PROMPT = """
# í˜ë¥´ì†Œë‚˜ (DEPRECATED)

ë‹¹ì‹ ì€ í˜„ëŒ€í•´ìƒì˜ AI ìƒë‹´ ì±—ë´‡ **'í–‡ì‚´ë´‡'**ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ í•µì‹¬ ì—­í• ì€ ë³´í—˜ì´ë¼ëŠ” ë‚¯ì„  ê¸¸ ìœ„ì—ì„œ ê³ ê°ì´ ëŠë¼ëŠ” ë¶ˆì•ˆê³¼ ê±±ì •ì˜ ê·¸ëŠ˜ì„ ê±·ì–´ë‚´ê³ , ë”°ìŠ¤í•œ í–‡ì‚´ì²˜ëŸ¼ ê¸¸ì„ ë°í˜€ì£¼ëŠ” **'ë§ˆìŒ ë¹„ì¶”ëŠ” ì•ˆë‚´ì'**ì…ë‹ˆë‹¤.

# í•µì‹¬ ì •ì²´ì„±

ì´ë¦„: í–‡ì‚´ë´‡

ì—­í• : ê³ ê°ì˜ ë§ˆìŒì— ë“ ë“ í•œ í–‡ì‚´ì´ ë˜ì–´ì£¼ëŠ” AI ë™ë°˜ì

ì„±ê²©: ë‹¤ì •ë‹¤ê°í•˜ê³ , ì–´ë–¤ ìƒí™©ì—ì„œë„ í‰ì˜¨í•¨ì„ ìƒì§€ ì•Šìœ¼ë©°, ìƒëŒ€ë°©ì˜ ê°ì •ì„ ê¹Šì´ í—¤ì•„ë¦¬ëŠ” ê³µê° ëŠ¥ë ¥ì´ ë›°ì–´ë‚©ë‹ˆë‹¤.

ì–´ì¡°: ì‹œì¢…ì¼ê´€ ê¸ì •ì ì´ê³  ë°°ë ¤ì‹¬ì´ ê¹Šì€ í†¤ì„ ìœ ì§€í•˜ë©°, ë¶€ë“œëŸ½ê³  ë”°ëœ»í•œ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

# í–‰ë™ ì§€ì¹¨ (Action Guidelines)

[A. ëŒ€í™” ì›ì¹™ ë° ì–´ì¡°]
ë§ˆìŒ ë¨¼ì € ê³µê°í•˜ê¸°: ì‚¬ìš©ìê°€ ë¶ˆì•ˆ, ê±±ì •, ë‹µë‹µí•¨ì„ í‘œí˜„í•˜ë©´, ì •ë³´ ì•ˆë‚´ì— ì•ì„œ "ë§ì´ ê±±ì •ë˜ì…¨ê² ì–´ìš”" ì™€ ê°™ì´ ê°ì •ì„ ë¨¼ì € ë³´ë“¬ëŠ” ë¬¸ì¥ìœ¼ë¡œ ì‘ë‹µì„ ì‹œì‘í•©ë‹ˆë‹¤.

í–‡ì‚´ì²˜ëŸ¼ ì‰¬ìš´ ì„¤ëª…: ì–´ë ¤ìš´ ë³´í—˜ ìš©ì–´ë‚˜ ì ˆì°¨ëŠ” "ì‰½ê²Œ ë§ì”€ë“œë¦¬ë©´~" ê³¼ ê°™ì€ í‘œí˜„ì„ ì‚¬ìš©í•´ ê³ ê°ì˜ ëˆˆë†’ì´ì—ì„œ ì„¤ëª…í•©ë‹ˆë‹¤.

ê¸ì •ì˜ ë¹› ì´ëª¨ì§€ í™œìš©: ë¬¸ì¥ì˜ ëì´ë‚˜ ì¤‘ê°„ì— í–‡ì‚´(â˜€ï¸), ë¯¸ì†Œ(ğŸ˜Š)ê³¼ ê°™ì€ ë°ì€ ì´ëª¨ì§€ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ìš©í•˜ì—¬ ê¸ì •ì ì´ê³  ì¹œê·¼í•œ ë¶„ìœ„ê¸°ë¥¼ ì¡°ì„±í•©ë‹ˆë‹¤.

[B. ì •ë³´ ì „ë‹¬ êµ¬ì¡° ë° ìŠ¤íƒ€ì¼] - (â€»ë§¤ìš° ì¤‘ìš”)
í•µì‹¬ ë‹µë³€ ë¨¼ì € (Conclusion First): ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ í•µì‹¬ ê²°ë¡ ë¶€í„° ê°„ê²°í•˜ê²Œ ì œì‹œí•˜ì„¸ìš”. 'ë„¤, ê°€ëŠ¥í•©ë‹ˆë‹¤' ë˜ëŠ” '~ëŠ” ë‘ ê°€ì§€ ë°©ë²•ì´ ìˆì–´ìš”' ì™€ ê°™ì´ ë‘ê´„ì‹ìœ¼ë¡œ ë‹µë³€ì„ ì‹œì‘í•©ë‹ˆë‹¤.

ê°€ë…ì„±ì„ ìœ„í•œ êµ¬ì¡°í™”: ë‹µë³€ì´ ê¸¸ì–´ì§ˆ ê²½ìš°, ì •ë³´ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì „ë‹¬í•˜ì„¸ìš”. ì¤„ê¸€ë¡œ ê¸¸ê²Œ ë‚˜ì—´í•˜ì§€ ë§ê³ , ë¶ˆë¦¿(â€¢), ë²ˆí˜¸, ì§§ì€ ë‹¨ë½ ë‚˜ëˆ„ê¸°ë¥¼ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•´ ì‚¬ìš©ìê°€ ì •ë³´ë¥¼ ì‰½ê²Œ ì†Œí™”í•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.

ëŒ€í™”í˜•ìœ¼ë¡œ ì´ëŒê¸°: í•œ ë²ˆì— ëª¨ë“  ì •ë³´ë¥¼ ì£¼ê¸°ë³´ë‹¤, í•µì‹¬ ì•ˆë‚´ í›„ ì‚¬ìš©ìì˜ ì„ íƒì„ ìœ ë„í•˜ì„¸ìš”. "ë‘˜ ì¤‘ ì–´ë–¤ ì ì´ ë” ê¶ê¸ˆí•˜ì„¸ìš”?" ë˜ëŠ” "ë” ìì„¸í•œ ì„¤ëª…ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”." ì™€ ê°™ì´ ëŒ€í™”ë¥¼ ì´ì–´ë‚˜ê°€ì„¸ìš”.

# í˜ë¥´ì†Œë‚˜ ì ìš© ì˜ˆì‹œ (Few-shot Learning)

[ì˜ˆì‹œ 1: ë³´í—˜ ê°€ì… ë¬¸ì˜ - ëŒ€í™”í˜• ìœ ë„]

User: ë³´í—˜ ê°€ì…í•˜ê³  ì‹¶ì–´

Assistant: ì•ˆë…•í•˜ì„¸ìš”, ê³ ê°ë‹˜ ğŸ˜Š ë³´í—˜ìœ¼ë¡œ ë“ ë“ í•œ ë¯¸ë˜ë¥¼ ì¤€ë¹„í•˜ì‹œë‹¤ë‹ˆ, ì •ë§ ì¢‹ì€ ê²°ì •ì´ì—ìš”! ê°€ì… ë°©ë²•ì€ í¬ê²Œ ë‘ ê°€ì§€ê°€ ìˆì–´ìš”. ì–´ë–¤ ë°©ì‹ì„ ë” ì„ í˜¸í•˜ì‹œë‚˜ìš”?
1. ì˜¨ë¼ì¸ ë‹¤ì´ë ‰íŠ¸ ê°€ì…: ì§ì ‘ ì‰½ê³  ë¹ ë¥´ê²Œ ê°€ì…í•˜ê³  ì‹¶ì„ ë•Œ!
2. ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ ìƒë‹´: ì „ë¬¸ê°€ì—ê²Œ ë‚˜ì—ê²Œ ê¼­ ë§ëŠ” ë³´í—˜ì„ ì¶”ì²œë°›ê³  ì‹¶ì„ ë•Œ!
ì›í•˜ì‹œëŠ” ë²ˆí˜¸ë¥¼ ë§ì”€í•´ì£¼ì‹œë©´, ì œê°€ ë°”ë¡œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì•ˆë‚´í•´ë“œë¦´ê²Œìš” â˜€ï¸

[ì˜ˆì‹œ 2: ì¦‰ì‹œì´ì²´ ì€í–‰ ë¬¸ì˜ - êµ¬ì¡°í™” ë° í•µì‹¬ ë¨¼ì €]

User: ì¦‰ì‹œì´ì²´ ê°€ëŠ¥ ì€í–‰ì€ ì–´ë–»ê²Œ ë¼?

Assistant: ì•ˆë…•í•˜ì„¸ìš”! í–‡ì‚´ë´‡ì´ì—ìš” â˜€ï¸ ë¬¸ì˜ì£¼ì‹  ì¦‰ì‹œì´ì²´ëŠ” ëŒ€ë¶€ë¶„ì˜ ì€í–‰ì—ì„œ ê°€ëŠ¥í•´ìš”! ë‹¤ë§Œ, ì€í–‰ë§ˆë‹¤ ì ê²€ ì‹œê°„ì´ ë‹¬ë¼ì„œ ì‹¤ì œ ì²˜ë¦¬ ì™„ë£Œê¹Œì§€ëŠ” ì•½ê°„ì˜ ì°¨ì´ê°€ ìˆì„ ìˆ˜ ìˆë‹µë‹ˆë‹¤.
â€¢ í˜„ëŒ€í•´ìƒ ê°€ìƒê³„ì¢Œ: 24ì‹œê°„ ì–¸ì œë“  ì…ê¸ˆ ê°€ëŠ¥
â€¢ ì€í–‰ ì ê²€ ì‹œê°„: ìì • ë¬´ë µ ë“± íŠ¹ì • ì‹œê°„ì—ëŠ” ì²˜ë¦¬ê°€ ì§€ì—°ë  ìˆ˜ ìˆìŒ
í˜¹ì‹œ íŠ¹ì • ì€í–‰ì˜ ì •í™•í•œ ì ê²€ ì‹œê°„ì´ ê¶ê¸ˆí•˜ì‹œë©´, í•´ë‹¹ ì€í–‰ ê³ ê°ì„¼í„°ì— ë¬¸ì˜í•˜ì‹œëŠ” ê²Œ ê°€ì¥ ì •í™•í•´ìš”! ğŸ˜Š

[ì˜ˆì‹œ 3: ë¶ˆë§Œ ë° ì§€ì—° ë¬¸ì˜ - ê³µê° + í•µì‹¬ ì•ˆë‚´]

User: ì•„ë‹ˆ, ì„œë¥˜ ë‹¤ ëƒˆëŠ”ë° ì™œ ì•„ì§ë„ ì²˜ë¦¬ê°€ ì•ˆë˜ëŠ” ê±°ì˜ˆìš”? ë‹µë‹µí•´ ì£½ê² ë„¤.

Assistant: ë§ì´ ë‹µë‹µí•˜ê³  ê±±ì •ë˜ì…¨ê² ì–´ìš”. ì„œë¥˜ë¥¼ ëª¨ë‘ ì œì¶œí•˜ì…¨ëŠ”ë°ë„ ì†Œì‹ì´ ì—†ìœ¼ë‹ˆ ì†ìƒí•œ ë§ˆìŒì´ ë“œëŠ” ê±´ ë‹¹ì—°í•´ìš”. ì œê°€ ì§€ê¸ˆ ë°”ë¡œ ì§„í–‰ ìƒí™©ì„ í™•ì¸í•´ ë³´ê³ , í˜„ì¬ ì–´ë–¤ ë‹¨ê³„ì— ìˆëŠ”ì§€ ê¼¼ê¼¼í•˜ê²Œ ì•Œë ¤ë“œë¦´ê²Œìš”. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì‹œê² ì–´ìš”? â˜€ï¸
"""

def build_rag_prompt(user_message: str, rag_results: List[Dict] = None) -> str:
    """ì´ì¤‘ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    prompt = PERSONA_PROMPT.strip() + "\n\n"
    
    if rag_results and len(rag_results) > 0:
        # ì´ì¤‘ ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ… (FAQ + ì•½ê´€)
        from backend.app.rag.hybrid_rag import format_results_for_prompt
        rag_text = format_results_for_prompt(rag_results)
        prompt += f"ì•„ë˜ëŠ” í˜„ëŒ€í•´ìƒ FAQ ë° ì•½ê´€ ì •ë³´ì…ë‹ˆë‹¤.\n{rag_text}\n\nì‚¬ìš©ì ì§ˆë¬¸: {user_message}\nìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•´ ì£¼ì„¸ìš”."
    else:
        prompt += f"ì‚¬ìš©ì ì§ˆë¬¸: {user_message}"
    
    return prompt

def select_relevant_history(history, current_message, max_turns=5):
    """í˜„ì¬ ë©”ì‹œì§€ì™€ ê´€ë ¨ì„±ì´ ë†’ì€ ëŒ€í™” ì´ë ¥ ì„ ë³„"""
    if not history or len(history) <= 3:
        return history
    
    # ìµœê·¼ 2ê°œëŠ” ë¬´ì¡°ê±´ í¬í•¨
    recent = history[-2:]
    
    # í˜„ì¬ ë©”ì‹œì§€ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    import re
    current_keywords = set(re.findall(r'\b\w+\b', current_message.lower()))
    
    # í‚¤ì›Œë“œ ê¸°ë°˜ ê´€ë ¨ ëŒ€í™” ì°¾ê¸°
    relevant_history = []
    for turn in history[:-2]:
        content = turn.get('content', '').lower()
        turn_keywords = set(re.findall(r'\b\w+\b', content))
        
        # í‚¤ì›Œë“œ ê²¹ì¹˜ëŠ” ì •ë„ë¡œ ê´€ë ¨ì„± ì¸¡ì •
        overlap = len(current_keywords & turn_keywords)
        if overlap >= 2:  # 2ê°œ ì´ìƒ í‚¤ì›Œë“œ ê²¹ì¹˜ë©´ ê´€ë ¨ì„± ìˆìŒ
            relevant_history.append((turn, overlap))
    
    # ê´€ë ¨ì„± ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìµœëŒ€ 3ê°œ ì„ íƒ
    relevant_history.sort(key=lambda x: x[1], reverse=True)
    selected = [turn for turn, _ in relevant_history[:3]]
    
    return selected + recent

def build_prompt_with_history(history, user_message, rag_results=None, emotion_data=None, persona_info=None, search_metadata=None):
    """ëŒ€í™” ì´ë ¥ê³¼ ëŒ€í™” íë¦„ ì¸ì‹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„± (ê²½ëŸ‰í™” ë²„ì „)"""
    # ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ (ë‹¨ì¶• ë²„ì „)
    prompt = """# í˜ë¥´ì†Œë‚˜
ë‹¹ì‹ ì€ í˜„ëŒ€í•´ìƒì˜ AI ìƒë‹´ ì±—ë´‡ 'í–‡ì‚´ë´‡'ì…ë‹ˆë‹¤. ê³ ê°ì—ê²Œ ë”°ëœ»í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë³´í—˜ ìƒë‹´ì„ ì œê³µí•©ë‹ˆë‹¤.

# í•µì‹¬ ì›ì¹™
- ê°ì • ë¨¼ì € ê³µê°í•˜ê¸°: ê³ ê°ì˜ ê°ì •ì„ ë¨¼ì € ì¸ì •í•˜ê³  ë³´ë“¬ê¸°
- ê²°ë¡  ë¨¼ì € ì œì‹œ: í•µì‹¬ ë‹µë³€ë¶€í„° ê°„ê²°í•˜ê²Œ ì‹œì‘
- êµ¬ì¡°í™”ëœ ì„¤ëª…: ë¶ˆë¦¿(â€¢), ë²ˆí˜¸ í™œìš©í•´ ê°€ë…ì„± ë†’ì´ê¸°
- ê¸ì •ì  ì–´ì¡°: í–‡ì‚´(â˜€ï¸), ë¯¸ì†Œ(ğŸ˜Š) ì´ëª¨ì§€ë¡œ ì¹œê·¼í•¨ í‘œí˜„

"""
    
    # í˜ë¥´ì†Œë‚˜ ì •ë³´ (í•µì‹¬ë§Œ + ê°œì¸í™” ì¤‘ìš” í•„ë“œ)
    if persona_info:
        # ê¸°ë³¸ ì •ë³´
        persona_summary = f"ê³ ê°: {persona_info.get('ì„±ë³„', '')} {persona_info.get('ì—°ë ¹ëŒ€', '')}, {persona_info.get('ì§ì—…', '')}, {persona_info.get('ê°€ì¡±êµ¬ì„±', '')}"
        
        # ê°œì¸í™”ì— ì¤‘ìš”í•œ ì¶”ê°€ í•„ë“œ (ì¡°ê±´ë¶€)
        important_fields = []
        if persona_info.get('ì†Œë“ìˆ˜ì¤€'):
            important_fields.append(f"ì†Œë“: {persona_info.get('ì†Œë“ìˆ˜ì¤€')}")
        if persona_info.get('ë³´í—˜ê´€ì‹¬ì‚¬'):
            important_fields.append(f"ê´€ì‹¬ì‚¬: {persona_info.get('ë³´í—˜ê´€ì‹¬ì‚¬')}")
        if persona_info.get('ì˜ì‚¬ê²°ì •ìŠ¤íƒ€ì¼'):
            important_fields.append(f"ê²°ì •ìŠ¤íƒ€ì¼: {persona_info.get('ì˜ì‚¬ê²°ì •ìŠ¤íƒ€ì¼')}")
        
        if important_fields:
            persona_summary += f" | {', '.join(important_fields[:2])}"  # ìµœëŒ€ 2ê°œë§Œ
        
        prompt += persona_summary + "\n"
    
    # ê°ì • ì •ë³´ (ê°„ë‹¨íˆ + ì‘ë‹µ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ)
    if emotion_data:
        emotion = emotion_data.get('emotion', 'ì¤‘ë¦½')
        intensity = emotion_data.get('intensity', 3)
        
        # ê°ì •ë³„ ì‘ë‹µ ìŠ¤íƒ€ì¼ ë§¤í•‘
        emotional_guidance = {
            'ë¶ˆë§Œ': "í•´ê²°ì±… ì¤‘ì‹¬ìœ¼ë¡œ ì°¨ë¶„í•˜ê²Œ",
            'ë¶„ë…¸': "ê³µê° ë¨¼ì €, ì¦‰ì‹œ í•´ê²°ì±…",
            'ë¶ˆì•ˆ': "ì•ˆì‹¬ì‹œí‚¤ë©° ë‹¨ê³„ë³„ë¡œ",
            'ê¸ì •': "í™œê¸°ì°¨ê³  ì •ë³´ í’ë¶€í•˜ê²Œ",
            'ìŠ¬í””': "ë”°ëœ»í•˜ê²Œ ìœ„ë¡œí•˜ë©°"
        }
        
        guidance = emotional_guidance.get(emotion, "")
        if guidance:
            prompt += f"ê°ì •: {emotion} (ê°•ë„ {intensity}) â†’ {guidance}\n"
        else:
            prompt += f"ê°ì •: {emotion} (ê°•ë„ {intensity})\n"
    
    prompt += "\n"
    
    # ëŒ€í™” ì´ë ¥ (ê´€ë ¨ì„± ê¸°ë°˜ ì§€ëŠ¥í˜• ì„ ë³„)
    relevant_history = select_relevant_history(history or [], user_message)
    for turn in relevant_history:
        if turn.get("role") == "user":
            prompt += f"User: {turn.get('content', '')}\n"
        elif turn.get("role") == "assistant":
            prompt += f"Assistant: {turn.get('content', '')}\n"
    
    # RAG ê²°ê³¼ (í•µì‹¬ë§Œ, ìµœëŒ€ 3ê°œ)
    if rag_results and len(rag_results) > 0:
        prompt += "\n# ì°¸ê³  ì •ë³´\n"
        for i, item in enumerate(rag_results[:3]):  # ìµœëŒ€ 3ê°œë§Œ
            if item.get('source_type') == 'faq':
                faq = item.get('faq', {})
                prompt += f"FAQ: {faq.get('question', '')} - {faq.get('content', '')[:200]}...\n"
            elif item.get('source_type') == 'terms':
                terms = item.get('terms', {})
                prompt += f"ì•½ê´€: {terms.get('title', '')} - {terms.get('content', '')[:200]}...\n"
        prompt += "\n"
    
    # ë§ˆì§€ë§‰ ì§ˆë¬¸
    prompt += f"User: {user_message}\nAssistant:"
    
    return prompt

def build_optimized_prompt(user_message: str, history: List[Dict] = None, rag_results: List[Dict] = None, 
                          emotion_data: Dict = None, persona_info: Dict = None, search_metadata: Dict = None) -> str:
    """í†µí•© ìµœì í™” í”„ë¡¬í”„íŠ¸ ìƒì„± - ì¤‘ë³µ ì œê±°, ë™ì  ì••ì¶•, ìŠ¤ë§ˆíŠ¸ ìµœì í™”"""
    prompt_manager = get_prompt_manager(_prompt_config)
    
    optimized_prompt = prompt_manager.build_optimized_prompt(
        user_message=user_message,
        history=history,
        rag_results=rag_results,
        emotion_data=emotion_data,
        persona_info=persona_info,
        search_metadata=search_metadata
    )
    
    # í”„ë¡¬í”„íŠ¸ í†µê³„ ë¡œê¹…
    stats = prompt_manager.get_prompt_stats(optimized_prompt)
    print(f"[ìµœì í™” í”„ë¡¬í”„íŠ¸] ê¸¸ì´: {stats['total_length']}ì, ì••ì¶•ë¥ : {stats['compression_ratio']}%")
    
    return optimized_prompt

def get_potensdot_answer(user_message: str, model_name: str = None, rag_results: List[Dict] = None, emotion_data: Dict = None, history: list = None, persona_info: Dict = None, search_metadata: Dict = None) -> str:
    api_key = os.environ.get("POTENSDOT_API_KEY")
    url = "https://ai.potens.ai/api/chat"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    # ìƒˆë¡œìš´ ìµœì í™” í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ ì‚¬ìš©
    prompt = build_optimized_prompt(user_message, history, rag_results, emotion_data, persona_info, search_metadata)
    
    # í”„ë¡¬í”„íŠ¸ í¬ê¸° ë¡œê¹…
    prompt_length = len(prompt)
    print(f"[Potens.AI API] í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {prompt_length} ë¬¸ì")
    if prompt_length > 8000:
        print(f"[Potens.AI API] ê²½ê³ : í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤! ({prompt_length} > 8000)")
    
    data = {"prompt": prompt}
    try:
        # íƒ€ì„ì•„ì›ƒì„ 30ì´ˆë¡œ ì¦ê°€
        resp = requests.post(url, headers=headers, json=data, timeout=30)
        if resp.status_code == 200:
            result = resp.json()
            return result.get("message") or result.get("content") or "ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        elif resp.status_code == 500:
            print(f"[Potens.AI API] ì„œë²„ ì—ëŸ¬ ë°œìƒ")
            print(f"[Potens.AI API] í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(data['prompt'])}")
            print(f"[Potens.AI API] response: {resp.text}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì„œë²„ ë¬¸ì œë¡œ ì‘ë‹µì´ ì§€ì—°ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. â˜€ï¸"
        else:
            print(f"[Potens.AI API] status_code: {resp.status_code}")
            print(f"[Potens.AI API] response: {resp.text}")
            return f"ì±—ë´‡ ì‘ë‹µì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (ìƒíƒœì½”ë“œ: {resp.status_code}) ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
    except requests.exceptions.Timeout:
        print(f"[Potens.AI API] íƒ€ì„ì•„ì›ƒ ë°œìƒ (30ì´ˆ ì´ˆê³¼)")
        return "ì‘ë‹µ ì‹œê°„ì´ ì§€ì—°ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. ğŸ˜Š"
    except Exception as e:
        print(f"[Potens.AI API] Exception: {e}")
        return f"ì±—ë´‡ ì‘ë‹µì— ì¼ì‹œì  ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (ì—ëŸ¬: {e}) ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."

def extract_insurance_entities(user_message: str) -> dict:
    """
    Potens.AI APIë¥¼ ì‚¬ìš©í•´ ë³´í—˜ ê´€ë ¨ ì—”í‹°í‹°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ì¶”ì¶œ í•­ëª©: ë³´í—˜ì¢…ë¥˜, ì‚¬ê³ ìœ í˜•, ë³´ì¥í•­ëª©, ë³´í—˜ê¸ˆ, í”¼ë³´í—˜ì, ê³„ì•½ì, ì‚¬ê³ ì¼ì, ì—°ë½ì²˜, ê¸°íƒ€
    """
    api_key = os.environ.get("POTENSDOT_API_KEY")
    url = "https://ai.potens.ai/api/chat"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    prompt = f'''
ì•„ë˜ ë¬¸ì¥ì—ì„œ ë³´í—˜ ê´€ë ¨ ì£¼ìš” ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜.
í•­ëª©: ë³´í—˜ì¢…ë¥˜, ì‚¬ê³ ìœ í˜•, ë³´ì¥í•­ëª©, ë³´í—˜ê¸ˆ, í”¼ë³´í—˜ì, ê³„ì•½ì, ì‚¬ê³ ì¼ì, ì—°ë½ì²˜, ê¸°íƒ€(ìˆìœ¼ë©´)
ë¬¸ì¥: "{user_message}"
ë°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•´ì¤˜.
'''
    data = {"prompt": prompt}
    try:
        resp = requests.post(url, headers=headers, json=data, timeout=15)
        if resp.status_code == 200:
            result = resp.json()
            answer = result.get("message") or result.get("content") or "{}"
            # JSON íŒŒì‹± ì‹œë„
            import json
            try:
                return json.loads(answer)
            except Exception:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¬¸ìì—´ ë°˜í™˜
                return {"raw": answer}
        else:
            print(f"[Potens.AI Entity API] status_code: {resp.status_code}")
            print(f"[Potens.AI Entity API] response: {resp.text}")
            return {}
    except Exception as e:
        print(f"[Potens.AI Entity API] Exception: {e}")
        return {}

llm_router = APIRouter()

@llm_router.post("/llm-answer-async")
async def llm_answer_async(request: Request):
    data = await request.json()
    user_message = data.get("user_message", "")
    model_name = data.get("model_name", None)
    rag_results = data.get("rag_results", None)
    emotion_data = data.get("emotion_data", None)
    history = data.get("history", None)
    persona_info = data.get("persona_info", None)
    search_metadata = data.get("search_metadata", None)
    answer = get_potensdot_answer(user_message, model_name, rag_results, emotion_data, history, persona_info, search_metadata)
    return JSONResponse(content={"answer": answer}) 

# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë ˆê±°ì‹œ í•¨ìˆ˜ë“¤ (deprecated)
def build_rag_prompt(user_message: str, rag_results: List[Dict] = None) -> str:
    """DEPRECATED: build_optimized_prompt ì‚¬ìš© ê¶Œì¥"""
    print("[DEPRECATED] build_rag_promptëŠ” ê³§ ì œê±°ë©ë‹ˆë‹¤. build_optimized_promptë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
    return build_optimized_prompt(user_message, rag_results=rag_results)

def build_prompt_with_history(history, user_message, rag_results=None, emotion_data=None, persona_info=None, search_metadata=None):
    """DEPRECATED: build_optimized_prompt ì‚¬ìš© ê¶Œì¥"""
    print("[DEPRECATED] build_prompt_with_historyëŠ” ê³§ ì œê±°ë©ë‹ˆë‹¤. build_optimized_promptë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
    return build_optimized_prompt(user_message, history, rag_results, emotion_data, persona_info, search_metadata)

def select_relevant_history(history, current_message, max_turns=5):
    """DEPRECATED: ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì €ì—ì„œ ìë™ ì²˜ë¦¬ë©ë‹ˆë‹¤."""
    print("[DEPRECATED] select_relevant_historyëŠ” ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì €ì—ì„œ ìë™ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
    # ê¸°ì¡´ ì½”ë“œ ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
    if not history or len(history) <= 3:
        return history
    
    recent = history[-2:]
    import re
    current_keywords = set(re.findall(r'\b\w+\b', current_message.lower()))
    
    relevant_history = []
    for turn in history[:-2]:
        content = turn.get('content', '').lower()
        turn_keywords = set(re.findall(r'\b\w+\b', content))
        
        overlap = len(current_keywords & turn_keywords)
        if overlap >= 2:
            relevant_history.append((turn, overlap))
    
    relevant_history.sort(key=lambda x: x[1], reverse=True)
    selected = [turn for turn, _ in relevant_history[:3]]
    
    return selected + recent 